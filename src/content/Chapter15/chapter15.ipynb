{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人脸生成和处理丢失的标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用GAN（）的有趣应用程序列表是无穷无尽的，我们将在另一个有前景的应用程序中面向生成展示基于CelebA数据库的GANs。我们还将演示如何使用GAN进行半监督学习对标签丢失的数据设置一个标签很差的数据集。                      \n",
    "本章将介绍以下主题：\n",
    "- 人脸生成\n",
    "- 具有生成对抗网络的半监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人脸生成\n",
    "\n",
    "在我们前面提到的章节中，生成器和判别器组成了CNN和DNN。\n",
    "- CNN是一种神经网络，它将图像的数百个像素编码成一个小尺寸的矢量，这是图像的总结。（集合成一个图像）\n",
    "- DNN是一个学习一些过滤器以从z恢复原始图像的网络，同样，判别器将输出1或0以指示（说明）输入图像是来自实际数据集还是由生成器生成，另一方面，生成器将尝试复制类似于基于潜在空间z的原始数据集的图像，这可能遵循高斯分布。因此，生成器的目标是学习原始数据集的分布，从而欺骗判别器，从而做出错误的决定。\n",
    "在这个部分，我们将尝试教生成器学习人脸图片分布，以至于它可以生成真实的人脸。\n",
    "对于大多数图形公司来说，生成类似人类的面孔是至关重要的，因为它们总是在为自己的应用程序寻找新面孔，在人造面孔方面，它为我们提供了人工智能怎样更加贴近人脸的线索。\n",
    "在这个例子中，我们将使用CelebA数据集。 CelebFaces属性数据集\n",
    "（CelebA）是一个大型的脸部属性数据集，有大约200K名人形象，每个都有40个属性注释。数据集涵盖了很多姿势变化，以及背景杂乱，所以CelebA非常多样化，并且有很好的注释。这包括：\n",
    "- 10,177个身份\n",
    "- 202,599张脸部图片\n",
    "- 每个图像有五个地标位置和40个二进制属性注释\n",
    "我们可以将此数据集用于除面部生成之外的许多计算机视觉应用，例如面部识别和定位，或面部属性检测。此图显示了在训练过程中，生成器发生错误后(或学习人脸分布)是如何接近真实图片的：\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/01.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据\n",
    "\n",
    "在本节中，我们将定义一些帮助我们下载的辅助函数CelebA数据集。 我们首先导入他们所需的包,执行命令如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image as pimg\n",
    "import math\n",
    "# 有些库会因为之后可能对某个功能进行删减，所以会有警告，而下面这部分的目的就是过滤掉警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 探索数据\n",
    "\n",
    "CelebA数据集包含超过20万个带注释的名人图像。 由于我们下面要使用GAN生成类似的图像，因此值得查看数据集中的一堆图像，看看它们的外观。在本节中，我们将定义一些辅助函数，用于可视化CelebA数据集中的一组图像。\n",
    "现在，让我们使用utils脚本来显示数据集中的一些图像。\n",
    "该计算机视觉任务的主要目的是使用GAN生成与名人数据集中的图像类似的图像，所以我们需要关注图像的脸部部分。为了关注图像的脸部，我们将删除不包含名人脸部的图像部分。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# 下载数据包celebA的路径\n",
    "gzip_filename = './data/img_align_celeba.zip'\n",
    "# 将数据集进行解压缩之后，数据集所在的路径\n",
    "img_dir = './data/img_align_celeba/'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# exits是为了验证数据集的压缩包是否存在，listdir的目的是拿到img_dir目录下所有的文件夹和文件的名字，并将每个都转换成列表中的元素\n",
    "if os.path.exists(gzip_filename) and len(os.listdir(img_dir)) == 0:\n",
    "    # 使用zipfile函数中ZipFile方法来打开数据集压缩包，并将此句柄使用gp在之后进行引用\n",
    "    with zipfile.ZipFile(gzip_filename) as gp:\n",
    "        # namelist是为了拿到压缩包中所有文件的名字，并针对每个文件进行extract即解压缩处理\n",
    "        for name in gp.namelist():\n",
    "            gp.extract(img_dir)\n",
    "else:\n",
    "    print('celebA is ready.')\n",
    "    \n",
    "    # 展示的数据集中的图片的数量\n",
    "show_nums = 16\n",
    "# 建立一个列表，此列表的目的是为了稍后进行存储PIL打开图片的对象\n",
    "imgs = []\n",
    "# 计算下总共有多少个图片\n",
    "count = len(os.listdir(img_dir))\n",
    "# 设置循环来从硬盘中读取图片\n",
    "for i in range(show_nums):\n",
    "    j = i + 1\n",
    "    # 从硬盘中读取图片，在每次循环都会读取一张，并将对象赋值给img以便之后添加到列表中\n",
    "    img = pimg.open(img_dir+'{:0>6}.jpg'.format(j))\n",
    "    # 将读到的图片对象添加到imgs列表中\n",
    "    imgs.append(img)\n",
    "# 设置一个4*4的画板，也即是能够显示16个图片的画板\n",
    "fig,axes = plt.subplots(4,4)\n",
    "# 对画板进行编号，并对画板中的每个小格显示一张图片\n",
    "for k,ax in enumerate(axes.flat):\n",
    "    # 将图片绘画到一个小格中\n",
    "    ax.imshow(imgs[k-1])\n",
    "    # 删除刻度\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "# 展示画板\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/1.1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建立模型\n",
    "\n",
    "现在，让我们从构建实现的核心开始，即开始计算图形。它主要包括以下部分：\n",
    "- 模型输入\n",
    "- 判别\n",
    "- 生成器\n",
    "- 模型损失\n",
    "- 模型优化\n",
    "- 训练模式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 拿到图片，并将图片进行切割，只显示人的脸部\n",
    "def get_image(image_path, width, height, mode):\n",
    "\n",
    "    # 从硬盘中读取图片，并在之后使用image进行引用\n",
    "    image = pimg.open(image_path)\n",
    "\n",
    "    # 如果图片的大小不等于只有脸部的样子的话\n",
    "    if image.size != (width, height):  \n",
    "        \n",
    "        # 对脸部的大小进行规划\n",
    "        face_width = face_height = 108\n",
    "        # 计算要切割的图片的左侧像素点\n",
    "        j = (image.size[0] - face_width) // 2\n",
    "        # 计算要切割的图片的上侧像素点\n",
    "        i = (image.size[1] - face_height) // 2\n",
    "        # 对图片进行切割，只保留了图片中脸部\n",
    "        image = image.crop([j, i, j + face_width, i + face_height])\n",
    "        # 对图片的边缘进行处理\n",
    "        image = image.resize([width, height], pimg.BILINEAR)\n",
    "\n",
    "    # 将裁剪过的图片转换下各个像素点的值，并将每个处理过的图片都用数组的形式作为函数的返回值\n",
    "    return np.array(image.convert(mode))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# 按照批次将图片进行处理\n",
    "def get_batch(image_files, width, height, mode):\n",
    "    # 从image_files中依次拿到图片，并将图片转交给get_image函数进行处理，将处理的结果以列表形式储存之后，再转换成数组的形式，其中每个数字都是float32格式\n",
    "    data_batch = np.array(\n",
    "        [get_image(sample_file, width, height, mode) for sample_file in image_files]).astype(np.float32)\n",
    "\n",
    "    # 将之前处理过的数据的格式转化成特定的形式（有四个元素的元祖）\n",
    "    if len(data_batch.shape) < 4:\n",
    "        a_batch = data_batch.reshape(data_batch.shape + (1,))\n",
    "\n",
    "    return data_batch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# 设计一个类用来调用之前定义的函数，来处理从硬盘中读取到的图片\n",
    "class Dataset(object):\n",
    "\n",
    "    def __init__(self, dataset_name, data_files):\n",
    "\n",
    "        DATASET_CELEBA_NAME = 'celeba'\n",
    "        IMAGE_WIDTH = 28\n",
    "        IMAGE_HEIGHT = 28\n",
    "\n",
    "        if dataset_name == DATASET_CELEBA_NAME:\n",
    "            self.image_mode = 'RGB'\n",
    "            image_channels = 3\n",
    "\n",
    "\n",
    "        self.data_files = data_files\n",
    "        self.shape = len(data_files), IMAGE_WIDTH, IMAGE_HEIGHT, image_channels\n",
    "\n",
    "    # 按照批次来读取\n",
    "    def get_batches(self, batch_size):\n",
    "\n",
    "        IMAGE_MAX_VALUE = 255\n",
    "\n",
    "        # 用索引的形式进行读取\n",
    "        current_index = 0\n",
    "        while current_index + batch_size <= self.shape[0]:\n",
    "            # 调用之前的函数来读取图片，并将图片进行处理之后返回给data_batch\n",
    "            data_batch = get_batch(\n",
    "                self.data_files[current_index:current_index + batch_size],\n",
    "                *self.shape[1:3],\n",
    "                self.image_mode)\n",
    "\n",
    "            # 更新索引值\n",
    "            current_index += batch_size\n",
    "\n",
    "            # 用生成器的形式分批次将处理过的数据迭代出去\n",
    "            yield data_batch / IMAGE_MAX_VALUE - 0.5\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ```python\n",
    "# 将随机生成的数字按照图片的规则进行显示\n",
    "def images_square_grid(images, mode):\n",
    "\n",
    "\n",
    "    save_size = math.floor(np.sqrt(images.shape[0]))\n",
    "\n",
    "    \n",
    "    images = (((images - images.min()) * 255) / (images.max() - images.min())).astype(np.uint8)\n",
    "\n",
    "    # 将图片按照正方形进行排列\n",
    "    images_in_square = np.reshape(\n",
    "            images[:save_size*save_size],\n",
    "            (save_size, save_size, images.shape[1], images.shape[2], images.shape[3]))\n",
    "    if mode == 'L':\n",
    "        images_in_square = np.squeeze(images_in_square, 4)\n",
    "\n",
    "\n",
    "    # 使用PIL来重新构建一个图片对象\n",
    "    new_im = pimg.new(mode, (images.shape[1] * save_size, images.shape[2] * save_size))\n",
    "    for col_i, col_images in enumerate(images_in_square):\n",
    "        for image_i, image in enumerate(col_images):\n",
    "            # 从数组中构建一个图片内存\n",
    "            im = pimg.fromarray(image, mode)\n",
    "            # 将内存中的图片粘贴到new_im中\n",
    "            new_im.paste(im, (col_i * images.shape[1], image_i * images.shape[2]))\n",
    "\n",
    "    return new_im\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模型输入\n",
    "\n",
    "在本节中，我们将实现一个辅助函数，这样我们就可以定义模型输入占位符，这个占位符将负责把数据输入计算图。这些辅助函数应该能够创建三个主要占位符：\n",
    "- 来自数据集的实际输入图像，其中包含的尺寸有（批量大小，输入图像宽度，输入图像高度，通道数）\n",
    "- 潜在空间Z，将由发生器用于生成假图像学习率占位符\n",
    "- 辅助函数将返回这三个输入占位符的元组。接下来我们继续定义此功能：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义一个inputs函数\n",
    "def inputs(img_width,img_height,img_channels,latent_space_z_dim):\n",
    "    # 使用占位符来定义一个存储样本图片的变量\n",
    "    true_inputs = tf.placeholder(tf.float32,(None,img_width,img_height,img_channels),'true_inputs')\n",
    "    # 使用占位符来定义一个存储生成器生成图片的变量\n",
    "    l_space_inputs = tf.placeholder(tf.float32,(None,latent_space_z_dim),'l_space_inputs')\n",
    "    # 使用占位符来定义一个模型学习的精度\n",
    "    model_learning_rate = tf.placeholder(tf.float32,name='model_learning_rate')\n",
    "    return true_inputs,l_space_inputs,model_learning_rate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 判别器\n",
    "\n",
    "接下来，我们需要实现网络的判别器部分，这将用于判断传入的数据是来自真实数据集还是由生成器生成的数据集。同样，我们可以用tf.variable_scope的TensorFlow功能使用判别器为一些变量加前缀，以便于我们可以检索和重新使用它们。所以，让我们定义一个函数，它将返回判别器的二进制输出以及logit值："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义判别器\n",
    "def discriminator(input_imgs,reuse=False):\n",
    "    # 创建变量并规定了它的作用域\n",
    "    with tf.variable_scope('discriminator',reuse=reuse):\n",
    "        # 设置泄露线性整型激活函数中的参数\n",
    "        leaky_param_alpha = 0.2\n",
    "        # 进行第一次卷积操作\n",
    "        conv_layer_1 = tf.layers.conv2d(input_imgs,64,5,2,'same')\n",
    "        # 进行第一次激活函数处理\n",
    "        leaky_relu_output = tf.maximum(leaky_param_alpha*conv_layer_1,conv_layer_1)\n",
    "        # 进行第二次卷积操作\n",
    "        conv_layer_2 = tf.layers.conv2d(leaky_relu_output,128,5,2,'same')\n",
    "        # 用batch_normalization来处理卷积之后的结果，防止模型卡在这个地方\n",
    "        noramlized_output = tf.layers.batch_normalization(conv_layer_2,training=True)\n",
    "        # 进行第二次激活函数处理\n",
    "        leay_relu_output = tf.maximum(leaky_param_alpha*noramlized_output,noramlized_output)\n",
    "        # 进行第三次卷积神经操作\n",
    "        conv_layer_3 = tf.layers.conv2d(leay_relu_output,256,5,2,'same')\n",
    "        # 再次使用batch_normalization处理卷积之后的结果\n",
    "        noramlized_output = tf.layers.batch_normalization(conv_layer_3,training=True)\n",
    "        # 进行第三次激活函数处理\n",
    "        leaky_relu_output = tf.maximum(leaky_param_alpha*noramlized_output,noramlized_output)\n",
    "        # 将处理过的图片进行压平处理，也即是转换成多维数组\n",
    "        flattened_output = tf.reshape(leaky_relu_output,(-1,4*4*256))\n",
    "        # 将压平的数据交给全连接神经网络处理\n",
    "        logits_layer = tf.layers.dense(flattened_output,1)\n",
    "        # 将全连接神经网络处理的结果交给sigmoid激活函数进行数据压缩\n",
    "        output = tf.sigmoid(logits_layer)\n",
    "\n",
    "        return output,logits_layer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 生成器\n",
    "\n",
    "现在，是时候实现网络的第二部分，也就是使用潜在空间z复制原始输入图像。我们也将使用tf.variable_scope来实现此功能。接下来我们定义可以把生成器返回生成图像的函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# 定义GAN中的生成器\n",
    "def generator(z_latent_space,output_channel_dim,is_train=True):\n",
    "    # 创建变量并规定了它的作用域\n",
    "    with tf.variable_scope('generator',reuse=not is_train):\n",
    "        # 设置泄露线性整型激活函数中的参数\n",
    "        leaky_param_alpha = 0.2\n",
    "        # 定义全连接层\n",
    "        fully_connected_layer = tf.layers.dense(z_latent_space,2*2*512)\n",
    "        # 将全连接层的输出结果进行结构的变化\n",
    "        reshaped_output = tf.reshape(fully_connected_layer,(-1,2,2,512))\n",
    "        # 将变化后的数据使用batch_normalization进行处理，防止在训练过程中陷入卡顿\n",
    "        normalized_output = tf.layers.batch_normalization(reshaped_output,training=is_train)\n",
    "        # 对上面处理的数据应用激活函数处理\n",
    "        leaky_relu_output = tf.maximum(leaky_param_alpha*normalized_output,normalized_output)\n",
    "        # 进行第一次转置卷积\n",
    "        conv_layer_1 = tf.layers.conv2d_transpose(leaky_relu_output,256,5,2,'same')\n",
    "        # 对转置卷积之后的结果应用batch_normalization来防止在训练过程中的卡顿\n",
    "        normalized_output = tf.layers.batch_normalization(conv_layer_1,training=is_train)\n",
    "        # 对上面进行防卡顿处理之后，再应用泄露线性整型激活函数\n",
    "        leaky_relu_output = tf.maximum(leaky_param_alpha*normalized_output,normalized_output)\n",
    "        # 进行第二次转置卷积\n",
    "        conv_layer_2 = tf.layers.conv2d_transpose(leaky_relu_output,128,5,2,'same')\n",
    "        # 对第二次转置卷积的结果进行batch_normalization处理\n",
    "        normalized_output = tf.layers.batch_normalization(conv_layer_2,training=is_train)\n",
    "        # 对处理过的数据交给激活函数来进行处理\n",
    "        leaky_relu_output = tf.maximum(leaky_param_alpha*normalized_output,normalized_output)\n",
    "        # 进行第三次转置卷积\n",
    "        logits_layer = tf.layers.conv2d_transpose(leaky_relu_output,output_channel_dim,5,2,'same')\n",
    "        # 将卷积之后的结果交给tanh激活函数进行处理\n",
    "        output = tf.tanh(logits_layer)\n",
    "\n",
    "        return output\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模型损失\n",
    "\n",
    "现在出现了一个棘手的部分，也就是在上一章中讨论过的计算判别器和生成器的损耗。所以，我们定义这样的函数，它将利用先前定义的生成器和判别器函数："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义模型损失\n",
    "def model_losses(input_actual,input_latent_z,out_channel_dim):\n",
    "    # 先使用生成器来生成虚假的图片信息\n",
    "    gen_model = generator(input_latent_z,out_channel_dim)\n",
    "    # 让判别器进行根据样本信息来进行判断\n",
    "    disc_model_true,disc_logits_true = discriminator(input_actual)\n",
    "    # 让判别器对由生成器生成的数据进行判断\n",
    "    disc_model_fake,disc_logits_fake = discriminator(gen_model,reuse=True)\n",
    "    # 根据交叉熵来进行模型损失的评估，此处使用的数据是经过判别器判断为真的数据\n",
    "    disc_loss_true = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_logits_true,\n",
    "                                                                            labels=tf.ones_like(disc_model_true)))\n",
    "    # 根据交叉熵来进行模型损失的评估，此处使用的数据是经过判别器判断为假的数据\n",
    "    disc_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_logits_fake,\n",
    "                                                                            labels=tf.zeros_like(disc_model_fake)))\n",
    "    # 根据交叉熵来进行模型损失的评估，此处使用的数据是经过判别器判断为假的数据，但是将标签设置为了真\n",
    "    gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_logits_fake,\n",
    "                                                                      labels=tf.ones_like(disc_model_fake)))\n",
    "    # 计算总的判别器的损失\n",
    "    disc_loss = disc_loss_true + disc_loss_fake\n",
    "    return disc_loss,gen_loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模型优化\n",
    "\n",
    "最后，在运行我们的模型之前，我们需要实现这个任务的优化标准。下面继续使用之前使用的命名约定来检索判别器和生成器的可训练参数并训练它们："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# 设置模型的优化函数\n",
    "def model_optimizer(disc_loss,gen_loss,learning_rete,beta11):\n",
    "    # 将训练过程总使用的变量名全部提取出来\n",
    "    trainable_vars = tf.trainable_variables()\n",
    "    # 将训练过程的变量按照命名方式进行分类\n",
    "    disc_vars = [var for var in trainable_vars if var.name.startswith('discriminator')]\n",
    "    gen_vars = [var for var in trainable_vars if var.name.startswith('generator')]\n",
    "    # 根据变量的命名方式，然后对其所代表的训练过程按照要求进行模型优化\n",
    "    disc_train_opt = tf.train.AdamOptimizer(learning_rete,\n",
    "                                        beta1=beta11).minimize(disc_loss,var_list=disc_vars)\n",
    "    # 收集特定的变量名\n",
    "    update_operations = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    # 根据变量是否是以generator起始，来进行区分\n",
    "    gen_updates = [opt for opt in update_operations if opt.name.startswith('generator')]\n",
    "    # 根据变量之间的相互依赖关系来进行模型的优化\n",
    "    with tf.control_dependencies(gen_updates):\n",
    "        gen_train_opt = tf.train.AdamOptimizer(learning_rete,\n",
    "                                       beta1=beta11).minimize(gen_loss,var_list=gen_vars)\n",
    "\n",
    "    return disc_train_opt,gen_train_opt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 展示下生成器生成的结果\n",
    "def show_generator_output(sess,num_images,input_latent_z,output_channel_dim,img_mode):\n",
    "    # 对图片的色彩数进行设置\n",
    "    cmap = False if img_mode == 'RGB' else True\n",
    "    # 将input_latent_z的色彩种类取出来，如果是彩色则取的是3，黑白则是1\n",
    "    latent_space_z_dim = input_latent_z.get_shape().as_list()[-1]\n",
    "    # 根据图片的数量和色彩通道数来随机生成新的数组\n",
    "    examples_z = np.random.uniform(-1,1,size=[num_images,latent_space_z_dim])\n",
    "    # 根据随机生成的数组，来让生成器处理\n",
    "    examples = sess.run(generator(input_latent_z,output_channel_dim,False),\n",
    "                        feed_dict ={input_latent_z:examples_z})\n",
    "    # 调用images_square_grid将生成器生成的数组进行处理\n",
    "    images_grid = images_square_grid(examples,img_mode)\n",
    "    # 将所编辑好的内容加载到画板中\n",
    "    plt.imshow(images_grid)\n",
    "    # 展示画板\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 训练模型\n",
    "\n",
    "现在，是时候训练模型，看看生成器如何在某种程度上通过生成非常接近原始CelebA数据集的图像来欺骗判别器。\n",
    "首先，让我们定义一个辅助函数，它将显示一些通过生成器生成的图像：\n",
    "然后，我们使用之前定义的辅助函数来构建模型输入，损失和优化标准。我们将它们堆叠在一起，并开始基于CelebA数据集训练我们的模型。启动培训的过程，可能需要一些时间，它取决于每个人的主机规格。\n",
    "经过一段时间对模型的训练，我们可以得到下面的图形。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义模型训练函数\n",
    "def model_train(epochs,batch_size,learning_rete,beta11,get_batches,input_data_shape,data_img_mode):\n",
    "    # 将数据集的格式交给单独的变量\n",
    "    image_width,image_height,image_channels,z_dims = input_data_shape\n",
    "    # 调用inputs函数，并将返回的结果交给相对应的变量\n",
    "    actual_input,z_input,learningRate = inputs(image_width,image_height,image_channels,z_dims)\n",
    "    # 调用model_losses函数，并将返回的结果交给相应的变量\n",
    "    disc_loss,gen_loss = model_losses(actual_input,z_input,image_channels)\n",
    "    # 调用model_optimizer函数，并将返回的结果交给相应的变量\n",
    "    disc_opt,gen_opt = model_optimizer(disc_loss,gen_loss,learning_rete,beta11)\n",
    "    # 循环次数变量\n",
    "    steps = 0\n",
    "    # 每循环50次，打印一次模型的损失\n",
    "    print_every = 50\n",
    "    # 每循环100次，打印一下生成器生成的图片\n",
    "    show_every = 100\n",
    "    # 设置每次循环时产生的模型损失\n",
    "    model_loss = []\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # 对所有的tensorflow的变量进行初始化，准备开始进行训练\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # 根据训练周期进行循环\n",
    "        for epoch in range(epochs):\n",
    "            # 根据数据集的批次来进行循环\n",
    "            for batch_images in get_batches(batch_size):\n",
    "                # 计算循环的次数\n",
    "                steps += 1\n",
    "                batch_images *= 2.0\n",
    "                # 生成随机数据\n",
    "                z_sample = np.random.uniform(-1,1,(batch_size,z_dims))\n",
    "                # 对模型进行优化\n",
    "                _ = sess.run(disc_opt,feed_dict={actual_input:batch_images,z_input:z_sample,learningRate:learning_rete})\n",
    "                _ = sess.run(gen_opt,feed_dict={z_input:z_sample,learningRate:learning_rete})\n",
    "                # 每训练50次计算一次模型损失，并显示出来\n",
    "                if steps % print_every == 0:\n",
    "                    train_loss_disc = disc_loss.eval({z_input:z_sample,actual_input:batch_images})\n",
    "                    train_loss_gen = gen_loss.eval({z_input:z_sample})\n",
    "\n",
    "                    print('Epoch {}/{}\\t'.format(epoch + 1,epochs),\n",
    "                          'Discriminator Loss:{:.4f}\\t'.format(train_loss_disc),\n",
    "                          'Generator Loss:{:.4f}'.format(train_loss_gen))\n",
    "\n",
    "                    model_loss.append((train_loss_disc,train_loss_gen))\n",
    "                    # 每训练100次展示一次生成器生成的图片\n",
    "                if steps % show_every == 0:\n",
    "                    show_generator_output(sess,num_images,z_input,image_channels,data_img_mode)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# 每次训练从硬盘中读取的数据量\n",
    "train_batch_size = 512\n",
    "# 生成器生成的数组，与图片的大小有关\n",
    "z_dim = 100\n",
    "# 在进行模型优化时的模型精确度\n",
    "learning_rate = 0.002\n",
    "# 模型优化时的一个参数\n",
    "beta1 = 0.5\n",
    "# 只进行两个周期的训练\n",
    "num_epochs = 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 对数据集进行实例化\n",
    "celeba_dataset = Dataset('celeba',glob(os.path.join(img_dir,'*.jpg')))\n",
    "# 设置一个上下文管理器\n",
    "with tf.Graph().as_default():\n",
    "    # 调用model_train开始进行训练\n",
    "    model_train(num_epochs, train_batch_size,    learning_rate,  beta1,\n",
    "                celeba_dataset.get_batches, [28,28,3,train_batch_size],   'RGB')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Epoch 1/2\t Discriminator Loss:0.0032\t Generator Loss:7.0822\n",
    "    Epoch 1/2\t Discriminator Loss:0.0012\t Generator Loss:9.5755\n",
    "    ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/1.2.png?raw=true)\n",
    "    \n",
    "     Epoch 1/2\t Discriminator Loss:0.0010\t Generator Loss:9.1579\n",
    "    Epoch 1/2\t Discriminator Loss:0.0006\t Generator Loss:9.5570\n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/1.3.png?raw=true)\n",
    "    \n",
    "     Epoch 1/2\t Discriminator Loss:0.0005\t Generator Loss:10.2887\n",
    "    Epoch 1/2\t Discriminator Loss:0.0009\t Generator Loss:10.5652\n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/1.4.png?raw=true)\n",
    "    \n",
    "     Epoch 1/2\t Discriminator Loss:0.0003\t Generator Loss:10.9225\n",
    "    Epoch 2/2\t Discriminator Loss:0.0002\t Generator Loss:11.8593\n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/1.5.png?raw=true)\n",
    "   \n",
    "     Epoch 2/2\t Discriminator Loss:0.0001\t Generator Loss:12.7685\n",
    "    Epoch 2/2\t Discriminator Loss:0.0001\t Generator Loss:12.2158\n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/1.6.png?raw=true)\n",
    "    \n",
    "     Epoch 2/2\t Discriminator Loss:0.0001\t Generator Loss:12.7092\n",
    "    Epoch 2/2\t Discriminator Loss:0.0001\t Generator Loss:13.2471\n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/1.7.png?raw=true)\n",
    "    \n",
    "     Epoch 2/2\t Discriminator Loss:0.0000\t Generator Loss:13.4493\n",
    "    Epoch 2/2\t Discriminator Loss:0.0000\t Generator Loss:13.7767\n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/1.8.png?raw=true)\n",
    "   \n",
    "     Epoch 2/2\t Discriminator Loss:0.0000\t Generator Loss:13.5980\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成对抗网络的半监督学习\n",
    "\n",
    "半监督学习是一种技术，其中标记和未标记的数据都用来训练分类器。\n",
    "这种类型的分类器占用标记数据的一小部分和大量未标记数据（来自同一域）。它的目的是将这些数据源结合起来训练深度卷积神经网络（DCNN），来学习能够将新数据点映射到其期望结果的推断函数。\n",
    "在这个前沿，我们提出了一个GAN模型，使用一个非常小的标记训练集对街景房屋号码进行分类。实际上，该模型使用大约1.3％的原始SVHN训练标签，也就是1000（一千）标记的示例。我们使用一些从OpenAI（网站中找到）（http://arxiv.org/abs/1606.03498）\n",
    "\n",
    "### 直觉\n",
    "\n",
    "在构建用于生成图像的GAN时，我们同时训练了生成器和判别器。训练后，我们可以丢弃判别器，因为我们只是用它来训练生成器。\n",
    "下图是使用半监督学习GAN对11种分类问题的体系结构。\n",
    "\n",
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/02.png?raw=true)\n",
    "\n",
    "在半监督学习中，我们需要将判别器转换为多类分类器。这个新模型必须能够在测试集上很好地概括，即使我们没有很多用于训练的标记示例。另外，这次，在训练结束时，我们实际上可以扔掉生成器。这时候的角色已经更改。现在生成器仅用于在训练期间帮助判别器。换句话说，生成器充当不同的信息源，判别器从中获得原始的，未标记的训练数据。正如我们将看到的，这些未标记的数据是提高判别器性能的关键。此外，对于常规图像生成GAN，判别器仅具有一个角色。计算其输入是真实的还是非真实的,我们把它称为GAN问题的概率。\n",
    "然而，为了将判别器变为半监督分类器，除了GAN问题之外，判别器还必须学习每个原始数据集类的概率。换句话说，对于每个输入的图像，判别器必须学习它的概率。\n",
    "回想一下，对于图像生成GAN判别器，我们有一个sigmoid单位输出。这个输出值表示输入图像为真实的概率（值接近1），或假的概率（值接近0）。换句话说，从判别器的角度来看，接近1的值意味着样本可能来自训练集。同样，接近0的值意味着样本来自生成器网络的可能性更高。通过使用该概率，判别器能够将信号发送回生成器。这个信号允许生成器在训练期间调整其参数，从而可以提高其创建逼真图像的能力。\n",
    "我们必须将判别器（从之前的GAN）转换为11类分类器。为此，我们可以将其sigmoid输出转换为具有11级输出的softmax，前10位为SVHN数据集的个体类概率（零到九），以及来自生成器的所有伪图像的第11类。\n",
    "注意：如果我们将第11类概率设置为0，则前10个概率的总和表示使用sigmoid函数计算的相同概率。\n",
    "最后，我们需要设置损失，以便判别器可以同时做到：\n",
    "- 帮助生成器学习生成逼真的图像。 为此，我们必须指示判别器区分真假样本。\n",
    "- 使用生成器生成的图像以及标记和未标记的训练数据来帮助对数据集进行分类。\n",
    "\n",
    "总而言之，判别器有三种不同的训练数据来源：\n",
    "- 带标签的真实图像。（这些是像任何常规监督分类问题中的图像标签对。\n",
    "- 没有标签的真实图像。（对于那些，判别器只学习这些图像是真实的。）\n",
    "- 来自生成器的图像。（为了使用这些，判别者学会将其归类为假的。）\n",
    "这些不同数据源的组合将使分类器能够从更广泛的角度进行学习。 反过来，这使得模型能够比仅使用1,000个标记的示例进行训练时更精确地执行推理。\n",
    "数据分析和预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pickle as pkl\n",
    "import time\n",
    "# 画图工具\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# 加载mat格式文件的库\n",
    "from scipy.io import loadmat\n",
    "# 深度学习的架构\n",
    "import tensorflow as tf\n",
    "\n",
    "extra_class = 0\n",
    "\n",
    "# 下载数据集所需要的库\n",
    "from urllib.request import urlretrieve\n",
    "# 判断数据集是否存在的库\n",
    "from os.path import isfile, isdir\n",
    "# 显示进度条的库\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "input_data_dir = 'input/'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 查看存放数据的文件夹是否存在，不存在就抛出异常\n",
    "if not isdir(input_data_dir):\n",
    "    raise Exception(\"Data directory doesn't exist!\")\n",
    "\n",
    "# 定义一个新类，让这个新类继承tqdm这个类，在这里目的是为了下载数据时可以显示进度条\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "# 查看train_32x32.mat是否存在，如果不存在，就从其它地方把它下载下来\n",
    "if not isfile(input_data_dir + \"train_32x32.mat\"):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='SVHN Training Set') as pbar:\n",
    "        urlretrieve(\n",
    "            'http://ufldl.stanford.edu/housenumbers/train_32x32.mat',\n",
    "            input_data_dir + 'train_32x32.mat',\n",
    "            pbar.hook)\n",
    "\n",
    "# 查看test_32x32.mat是否存在，如果不存在，就从其它地方把它下载下来\n",
    "if not isfile(input_data_dir + \"test_32x32.mat\"):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='SVHN Training Set') as pbar:\n",
    "        urlretrieve(\n",
    "            'http://ufldl.stanford.edu/housenumbers/test_32x32.mat',\n",
    "            input_data_dir + 'test_32x32.mat',\n",
    "            pbar.hook)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据分析和预处理\n",
    "\n",
    "在这个任务中，我们将使用SVHN数据集，它是斯坦福的街景房屋编号的缩写。因此，让我们开始该实现通过导入所需要的包开始：\n",
    "接下来，我们将定义一个帮助类来下载SVHN数据集（首先需要手动创建JOQVU@EBUB@EJS first）：\n",
    "让我们了解这些图像是什么样子的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# 加载用来训练的数据集\n",
    "train_data = loadmat(input_data_dir + 'train_32x32.mat')\n",
    "# 加载用来测试的测试集\n",
    "test_data = loadmat(input_data_dir + 'test_32x32.mat')\n",
    "\n",
    "# 生成随机的整型数字\n",
    "indices = np.random.randint(0, train_data['X'].shape[3], size=36)\n",
    "# 设置6*6的画板\n",
    "fig, axes = plt.subplots(6, 6, sharex=True, sharey=True, figsize=(5,5),)\n",
    "for ii, ax in zip(indices, axes.flatten()):\n",
    "    ax.imshow(train_data['X'][:,:,:,ii], aspect='equal')\n",
    "    # 不显示图片的轴\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "# 自动调整大小并展示画板结果\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.1.png?raw=true)\n",
    "\n",
    "接下来，我们需要将图像缩到-1到1之间，并且这个步骤是必要的，因此我们将使用tanh()函数，它将压缩生成器的输出值：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 将输入的图片进行缩放\n",
    "def scale_images(image, feature_range=(-1, 1)):\n",
    "    # 将图片上的每个像素点的值都缩放到0-1之间\n",
    "    image = ((image - image.min()) / (255 - image.min()))\n",
    "\n",
    "    # 将图片的值缩放到特征范围\n",
    "    min, max = feature_range\n",
    "    image = image * (max - min) + min\n",
    "    return image\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建立模型 \n",
    "\n",
    "在本节中，我们将构建测试所需要的所有部分，因此我们从定义输入开始，这些输入将用于给计算图提供数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Dataset:\n",
    "    def __init__(self, train_set, test_set, validation_frac=0.5, shuffle_data=True, scale_func=None):\n",
    "        \n",
    "        split_ind = int(len(test_set['y']) * (1 - validation_frac))\n",
    "        \n",
    "        self.test_input, self.valid_input = test_set['X'][:, :, :, :split_ind], test_set['X'][:, :, :, split_ind:]\n",
    "        \n",
    "        self.test_target, self.valid_target = test_set['y'][:split_ind], test_set['y'][split_ind:]\n",
    "        \n",
    "        self.train_input, self.train_target = train_set['X'], train_set['y']\n",
    "\n",
    " \n",
    "        # 因为门牌号都是由很多标签，但是我们在这里只假设有1000个\n",
    "        self.label_mask = np.zeros_like(self.train_target)\n",
    "        \n",
    "        self.label_mask[0:1000] = 1\n",
    "\n",
    "        self.train_input = np.rollaxis(self.train_input, 3)\n",
    "        \n",
    "        self.valid_input = np.rollaxis(self.valid_input, 3)\n",
    "        \n",
    "        self.test_input = np.rollaxis(self.test_input, 3)\n",
    "\n",
    "        if scale_func is None:\n",
    "            self.scaler = scale_images\n",
    "        else:\n",
    "            self.scaler = scale_func\n",
    "            \n",
    "        self.train_input = self.scaler(self.train_input)\n",
    "        \n",
    "        self.valid_input = self.scaler(self.valid_input)\n",
    "        \n",
    "        self.test_input = self.scaler(self.test_input)\n",
    "        \n",
    "        self.shuffle = shuffle_data\n",
    "\n",
    "    # 加载数据并处理 \n",
    "    def batches(self, batch_size, which_set=\"train\"):\n",
    "        input_name = which_set + \"_input\"\n",
    "        target_name = which_set + \"_target\"\n",
    "\n",
    "        # 获得target_name所代表的属性值的长度\n",
    "        num_samples = len(getattr(dataset, target_name))\n",
    "        if self.shuffle:\n",
    "            # 对长度进行索引\n",
    "            indices = np.arange(num_samples)\n",
    "            # 将索引进行打乱顺序\n",
    "            np.random.shuffle(indices)\n",
    "            # 重新设置input_name和target_name所对应的属性值\n",
    "            setattr(dataset, input_name, getattr(dataset, input_name)[indices])\n",
    "            setattr(dataset, target_name, getattr(dataset, target_name)[indices])\n",
    "            if which_set == \"train\":\n",
    "                dataset.label_mask = dataset.label_mask[indices]\n",
    "\n",
    "        # 提取dataset中对于变量的属性值\n",
    "        dataset_input = getattr(dataset, input_name)\n",
    "        dataset_target = getattr(dataset, target_name)\n",
    "\n",
    "        # 设置循环，依批次取出数据集中的数据\n",
    "        for jj in range(0, num_samples, batch_size):\n",
    "            # 根据索引来取出数据集中的数据\n",
    "            input_vals = dataset_input[jj:jj + batch_size]\n",
    "            target_vals = dataset_target[jj:jj + batch_size]\n",
    "\n",
    "            if which_set == \"train\":\n",
    "                # 包含了label_mask，以防止训练集中我们不知道的标签\n",
    "                # 通过生成器来批次将获得的数据提取出来\n",
    "                yield input_vals, target_vals, self.label_mask[jj:jj + batch_size]\n",
    "            else:\n",
    "                yield input_vals, target_vals\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模型输入\n",
    "\n",
    "首先，我们将定义模型输入参数，它将用于给计算模型提供数据的模型输入占位符\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义模型中的输入变量\n",
    "def inputs(actual_dim, z_dim):\n",
    "    # 使用占位符来定义之后需要的变量\n",
    "    inputs_actual = tf.placeholder(tf.float32, (None, *actual_dim), name='input_actual')\n",
    "    inputs_latent_z = tf.placeholder(tf.float32, (None, z_dim), name='input_latent_z')\n",
    "\n",
    "    target = tf.placeholder(tf.int32, (None), name='target')\n",
    "    label_mask = tf.placeholder(tf.int32, (None), name='label_mask')\n",
    "\n",
    "    return inputs_actual, inputs_latent_z, target, label_mask\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 生成器\n",
    "\n",
    "在这一部分中，我们将实现GAN网络的第一个核心部分。本部分的结构和实现将遵循最初的DCGAN文件："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义生成器\n",
    "def generator(latent_z, output_image_dim, reuse_vars=False, leaky_alpha=0.2, is_training=True, size_mult=128):\n",
    "    with tf.variable_scope('generator', reuse=reuse_vars):\n",
    "        # 定义一个全连接的神经网络\n",
    "        fully_conntected_1 = tf.layers.dense(latent_z, 4 * 4 * size_mult * 4)\n",
    "\n",
    "        # 把全连接神经网络的结果由两维转换成四维\n",
    "        reshaped_out_1 = tf.reshape(fully_conntected_1, (-1, 4, 4, size_mult * 4))\n",
    "        # 使用batch_normalization来对数据进行处理，防止在训练过程中卡顿\n",
    "        batch_normalization_1 = tf.layers.batch_normalization(reshaped_out_1, training=is_training)\n",
    "        # 使用泄露线性整型激活函数来处理上述数据\n",
    "        leaky_output_1 = tf.maximum(leaky_alpha * batch_normalization_1, batch_normalization_1)\n",
    "        # 进行转置卷积操作\n",
    "        conv_layer_1 = tf.layers.conv2d_transpose(leaky_output_1, size_mult * 2, 5, strides=2, padding='same')\n",
    "        # 使用batch_normalization来对数据进行处理\n",
    "        batch_normalization_2 = tf.layers.batch_normalization(conv_layer_1, training=is_training)\n",
    "        # 激活函数进行处理\n",
    "        leaky_output_2 = tf.maximum(leaky_alpha * batch_normalization_2, batch_normalization_2)\n",
    "        # 第二次转置卷积操作\n",
    "        conv_layer_2 = tf.layers.conv2d_transpose(leaky_output_2, size_mult, 5, strides=2, padding='same')\n",
    "        # 使用batch_normalization来对数据进行处理\n",
    "        batch_normalization_3 = tf.layers.batch_normalization(conv_layer_2, training=is_training)\n",
    "        # 激活函数进行处理\n",
    "        leaky_output_3 = tf.maximum(leaky_alpha * batch_normalization_3, batch_normalization_3)\n",
    "\n",
    "        # 定义输出层\n",
    "        logits_layer = tf.layers.conv2d_transpose(leaky_output_3, output_image_dim, 5, strides=2, padding='same')\n",
    "        # 将输出层交给tanh激活函数处理\n",
    "        output = tf.tanh(logits_layer)\n",
    "\n",
    "        return output\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 判别器\n",
    "\n",
    "现在，是时候建立GAN网络的第二个核心部分了——判别器。在以前的实现中，我们说过判别器将产生一个二进制输出，表示输入的图像来自真实数据集（1）还是由生成器（0）生成的数据集。这里的情况不同，所以判别器现在将是一个多类分类器。\n",
    "现在，让我们继续构建体系结构的判别器部分：\n",
    "不是在最后应用一个完全连接的层，我们将执行所谓的全球平均池（GAP），GAP取一个特征向量的空间维数的平均值。这将产生一个压缩的张量到一个值。\n",
    "例如，假设在一些卷积之后，我们得到了一个形状的输出张量：\n",
    "\n",
    "> [BATCH_SIZE,8,8,NUM_CHANNELS]\n",
    "\n",
    "为了应用全局变量，我们计算了8*8张量切片上的平均值。此操作将产生一个张量，其形状如下\n",
    "\n",
    "> [BATCH_SIZE,1,1,NUM_CHANNELS]\n",
    "\n",
    "在应用全局平均池之后，我们添加一个输出最终逻辑的完全连接的层，这些层形如下所示\n",
    "\n",
    ">[BATCH_SIZE,NUM_CLASSES]\n",
    "\n",
    "这些层代表每一个分类的得分。为了得到概率的分数，我们将使用TPGUNBY激活函数：\n",
    "最后，判别器函数将如下所示，\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义网络中的判别器\n",
    "def discriminator(input_x, reuse_vars=False, leaky_alpha=0.2, drop_out_rate=0., num_classes=10, size_mult=64):\n",
    "    # 定义变量的作用域\n",
    "    with tf.variable_scope('discriminator', reuse=reuse_vars):\n",
    "        # 定义为了防止过度拟合而随机丢弃的数据比例\n",
    "        drop_out_output = tf.layers.dropout(input_x, rate=drop_out_rate / 2.5)\n",
    "\n",
    "        # 对输入的数据进行卷积操作、激活函数处理、随机丢弃一部分数据等操作\n",
    "        conv_layer_3 = tf.layers.conv2d(input_x, size_mult, 3, strides=2, padding='same')\n",
    "        leaky_output_4 = tf.maximum(leaky_alpha * conv_layer_3, conv_layer_3)\n",
    "        leaky_output_4 = tf.layers.dropout(leaky_output_4, rate=drop_out_rate)\n",
    "\n",
    "        conv_layer_4 = tf.layers.conv2d(leaky_output_4, size_mult, 3, strides=2, padding='same')\n",
    "        batch_normalization_4 = tf.layers.batch_normalization(conv_layer_4, training=True)\n",
    "        leaky_output_5 = tf.maximum(leaky_alpha * batch_normalization_4, batch_normalization_4)\n",
    "\n",
    "        conv_layer_5 = tf.layers.conv2d(leaky_output_5, size_mult, 3, strides=2, padding='same')\n",
    "        batch_normalization_5 = tf.layers.batch_normalization(conv_layer_5, training=True)\n",
    "        leaky_output_6 = tf.maximum(leaky_alpha * batch_normalization_5, batch_normalization_5)\n",
    "        \n",
    "        leaky_output_6 = tf.layers.dropout(leaky_output_6, rate=drop_out_rate)\n",
    "\n",
    "        conv_layer_6 = tf.layers.conv2d(leaky_output_6, 2 * size_mult, 3, strides=1, padding='same')\n",
    "        batch_normalization_6 = tf.layers.batch_normalization(conv_layer_6, training=True)\n",
    "        leaky_output_7 = tf.maximum(leaky_alpha * batch_normalization_6, batch_normalization_6)\n",
    "\n",
    "        conv_layer_7 = tf.layers.conv2d(leaky_output_7, 2 * size_mult, 3, strides=1, padding='same')\n",
    "        batch_normalization_7 = tf.layers.batch_normalization(conv_layer_7, training=True)\n",
    "        leaky_output_8 = tf.maximum(leaky_alpha * batch_normalization_7, batch_normalization_7)\n",
    "\n",
    "        conv_layer_8 = tf.layers.conv2d(leaky_output_8, 2 * size_mult, 3, strides=2, padding='same')\n",
    "        batch_normalization_8 = tf.layers.batch_normalization(conv_layer_8, training = True)\n",
    "        leaky_output_9 = tf.maximum(leaky_alpha * batch_normalization_8, batch_normalization_8)\n",
    "        \n",
    "        leaky_output_9 = tf.layers.dropout(leaky_output_9, rate = drop_out_rate)\n",
    "\n",
    "        conv_layer_9 = tf.layers.conv2d(leaky_output_9, 2 * size_mult, 3, strides=1, padding='same')\n",
    "        leaky_output_10 = tf.maximum(leaky_alpha * conv_layer_9, conv_layer_9)\n",
    "\n",
    "        # 对上述处理的结果，计算各个维度的平均值\n",
    "        leaky_output_features = tf.reduce_mean(leaky_output_10, (1, 2))\n",
    "\n",
    "        # 设置一个变量来接收神经网络的结果\n",
    "        classes_logits = tf.layers.dense(leaky_output_features, num_classes + extra_class)\n",
    "\n",
    "        if extra_class:\n",
    "            actual_class_logits, fake_class_logits = tf.split(classes_logits, [num_classes, 1], 1)\n",
    "            assert fake_class_logits.get_shape()[1] == 1, fake_class_logits.get_shape()\n",
    "            fake_class_logits = tf.squeeze(fake_class_logits)\n",
    "        else:\n",
    "            actual_class_logits = classes_logits\n",
    "            fake_class_logits = 0.\n",
    "\n",
    "        # 计算各个维度上的最大值\n",
    "        max_reduced = tf.reduce_max(actual_class_logits, 1, keep_dims=True)\n",
    "        \n",
    "        stable_actual_class_logits = actual_class_logits - max_reduced\n",
    "\n",
    "        gan_logits = tf.log(tf.reduce_sum(tf.exp(stable_actual_class_logits), 1)) + tf.squeeze(\n",
    "            max_reduced) - fake_class_logits\n",
    "\n",
    "        # 对上述的结果进行softmax处理\n",
    "        softmax_output = tf.nn.softmax(classes_logits)\n",
    "\n",
    "        return softmax_output, classes_logits, gan_logits, leaky_output_features\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型损失\n",
    "\n",
    "现在是定义模型损失的时候了。首先，判别器损失将分为两部分： \n",
    "- 第一种代表GAN问题，即无监督损失。 \n",
    "- 第二种是计算个体的实际类概率，即监督损失。对于判别器的无监督损失，需要对实际的训练图像和生成图像进行区分。\n",
    "对于一般的GAN，一半时间内，判别器会从训练集中获取未标记的图像作为输入，另一半则从生成器获取假的、未标记的图像。\n",
    "对于判别器损失的第二部分，即监督损失，它需要建立在判别器逻辑的基础上。因此，我们将使用softmax交叉熵，因为这是一个多分类问题。\n",
    "最后，如下所示：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义模型损失\n",
    "def model_losses(input_actual, input_latent_z, output_dim, target, num_classes, label_mask, leaky_alpha=0.2,\n",
    "                     drop_out_rate=0.):\n",
    "\n",
    "        # 定义了生成器和判别器的矩阵大小\n",
    "        gen_size_mult = 32\n",
    "        disc_size_mult = 64\n",
    "\n",
    "        # 运行生成器和判别器\n",
    "        gen_model = generator(input_latent_z, output_dim, leaky_alpha=leaky_alpha, size_mult=gen_size_mult)\n",
    "        disc_on_data = discriminator(input_actual, leaky_alpha=leaky_alpha, drop_out_rate = drop_out_rate,size_mult = disc_size_mult)\n",
    "        \n",
    "        \n",
    "        disc_model_real, class_logits_on_data, gan_logits_on_data, data_features = disc_on_data\n",
    "        # 在生成器生成的结果上运行判别器\n",
    "        disc_on_samples = discriminator(gen_model, reuse_vars=True, leaky_alpha=leaky_alpha,\n",
    "                                        drop_out_rate=drop_out_rate, size_mult=disc_size_mult)\n",
    "        \n",
    "        disc_model_fake, class_logits_on_samples, gan_logits_on_samples, sample_features = disc_on_samples\n",
    "\n",
    "        # 使用交叉熵，计算了样本中被判为真的损失\n",
    "        disc_loss_actual = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_logits_on_data,\n",
    "                                                    labels=tf.ones_like(gan_logits_on_data)))\n",
    "        # 使用交叉熵，计算了样本中被判为假的损失\n",
    "        disc_loss_fake = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_logits_on_samples,\n",
    "                                                    labels=tf.zeros_like(gan_logits_on_samples)))\n",
    "        # 将target变量中各个维度中只有1个元素的维度清除掉\n",
    "        target = tf.squeeze(target)\n",
    "        classes_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=class_logits_on_data,\n",
    "                                                                        labels=tf.one_hot(target,num_classes + extra_class,dtype=tf.float32))\n",
    "        \n",
    "        classes_cross_entropy = tf.squeeze(classes_cross_entropy)\n",
    "        \n",
    "        label_m = tf.squeeze(tf.to_float(label_mask))\n",
    "        \n",
    "        disc_loss_class = tf.reduce_sum(label_m * classes_cross_entropy) / tf.maximum(1., tf.reduce_sum(label_m))\n",
    "        \n",
    "        disc_loss = disc_loss_class + disc_loss_actual + disc_loss_fake\n",
    "\n",
    "        # 设置了sample_features、data_features中各个维度的平均值\n",
    "        sampleMoments = tf.reduce_mean(sample_features, axis=0)\n",
    "        dataMoments = tf.reduce_mean(data_features, axis=0)\n",
    "\n",
    "        gen_loss = tf.reduce_mean(tf.abs(dataMoments - sampleMoments))\n",
    "        # cast将后面括号中的第一个元素中各个元素转换成第二个元素所代表的格式\n",
    "        prediction_class = tf.cast(tf.argmax(class_logits_on_data, 1), tf.int32)\n",
    "        # 对括号中两个数组进行对比，看是否相等\n",
    "        check_prediction = tf.equal(tf.squeeze(target), prediction_class)\n",
    "        # 对各个维度进行求和\n",
    "        correct = tf.reduce_sum(tf.to_float(check_prediction))\n",
    "        # 对各个维度进行求和\n",
    "        masked_correct = tf.reduce_sum(label_m * tf.to_float(check_prediction))\n",
    "\n",
    "        return disc_loss, gen_loss, correct, masked_correct, gen_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def model_optimizer(disc_loss, gen_loss, learning_rate, beta1):\n",
    "\n",
    "        # 获得所有的变量并将它们以名字的开头的格式进行区分\n",
    "        trainable_vars = tf.trainable_variables()\n",
    "        disc_vars = [var for var in trainable_vars if var.name.startswith('discriminator')]\n",
    "        gen_vars = [var for var in trainable_vars if var.name.startswith('generator')]\n",
    "        \n",
    "        for t in trainable_vars:\n",
    "            assert t in disc_vars or t in gen_vars\n",
    "\n",
    "        # 优化生成器和判别器的结果的损失\n",
    "        disc_train_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(disc_loss,var_list=disc_vars)\n",
    "        gen_train_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(gen_loss, var_list=gen_vars)\n",
    "        # 将learning_rate更新为原来的0.9倍\n",
    "        shrink_learning_rate = tf.assign(learning_rate, learning_rate * 0.9)\n",
    "\n",
    "        return disc_train_optimizer, gen_train_optimizer, shrink_learning_rate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模型优化器\n",
    "\n",
    "现在，我们定义模型优化器，它与我们前面定义的模型非常相似\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义生成对抗性网络\n",
    "class GAN:\n",
    "        def __init__(self, real_size, z_size, learning_rate, num_classes=10, alpha=0.2, beta1=0.5):\n",
    "            \n",
    "            tf.reset_default_graph()\n",
    "\n",
    "            self.learning_rate = tf.Variable(learning_rate, trainable=False)\n",
    "            \n",
    "            model_inputs = inputs(real_size, z_size)\n",
    "            \n",
    "            self.input_actual, self.input_latent_z, self.target, self.label_mask = model_inputs\n",
    "            \n",
    "            self.drop_out_rate = tf.placeholder_with_default(.5, (), \"drop_out_rate\")\n",
    "            # 计算模型损失\n",
    "            losses_results = model_losses(self.input_actual, self.input_latent_z,\n",
    "                                          real_size[2], self.target, num_classes,\n",
    "                                          label_mask=self.label_mask,\n",
    "                                          leaky_alpha=0.2,\n",
    "                                          drop_out_rate= self.drop_out_rate)\n",
    "            \n",
    "            self.disc_loss, self.gen_loss, self.correct, self.masked_correct, self.samples = losses_results\n",
    "            # 对模型进行优化\n",
    "            self.disc_opt, self.gen_opt, self.shrink_learning_rate = model_optimizer(self.disc_loss, self.gen_loss,\n",
    "                                                                                     self.learning_rate, beta1)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义函数来显示图片\n",
    "def view_generated_samples(epoch, samples, nrows, ncols, figsize=(5, 5)):\n",
    "    \n",
    "        fig, axes = plt.subplots(figsize=figsize, nrows=nrows, ncols=ncols,sharey=True, sharex=True)\n",
    "        \n",
    "        for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "            ax.axis('off')\n",
    "            img = ((img - img.min()) * 255 / (img.max() - img.min())).astype(np.uint8)\n",
    "            ax.set_adjustable('box-forced')\n",
    "            im = ax.imshow(img)\n",
    "\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        plt.show()\n",
    "        return fig, axes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# 定义训练函数\n",
    "def train(net, dataset, epochs, batch_size, figsize=(5, 5)):\n",
    "    \n",
    "        saver = tf.train.Saver()\n",
    "        sample_z = np.random.normal(0, 1, size=(50, latent_space_z_size))\n",
    "\n",
    "        samples, train_accuracies, test_accuracies = [], [], []\n",
    "        steps = 0\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # 根据周期进行训练\n",
    "            for e in range(epochs):\n",
    "                print(\"Epoch\", e )\n",
    "\n",
    "                num_samples = 0\n",
    "                num_correct_samples = 0\n",
    "                # 根据批次进行训练\n",
    "                for x, y, label_mask in dataset.batches(batch_size):\n",
    "                    assert 'int' in str(y.dtype)\n",
    "                    steps += 1\n",
    "                    num_samples += label_mask.sum()\n",
    "\n",
    "                    # 根据要求随机生成一些数组\n",
    "                    batch_z = np.random.normal(0, 1, size=(batch_size, latent_space_z_size))\n",
    "\n",
    "                    _, _, correct = sess.run([net.disc_opt, net.gen_opt, net.masked_correct],\n",
    "                                             feed_dict={net.input_actual: x, net.input_latent_z: batch_z,\n",
    "                                                        net.target: y, net.label_mask: label_mask})\n",
    "                    \n",
    "                    num_correct_samples += correct\n",
    "\n",
    "                sess.run([net.shrink_learning_rate])\n",
    "                # 计算在训练集中的准确率\n",
    "                training_accuracy = num_correct_samples / float(num_samples)\n",
    "\n",
    "                print(\"\\t\\tClassifier train accuracy: \", training_accuracy)\n",
    "\n",
    "                num_samples = 0\n",
    "                num_correct_samples = 0\n",
    "                # 从测试集中依批次拿到数据并进行测试准确率\n",
    "                for x, y in dataset.batches(batch_size, which_set=\"test\"):\n",
    "                    assert 'int' in str(y.dtype)\n",
    "                    num_samples += x.shape[0]\n",
    "\n",
    "                    correct, = sess.run([net.correct], feed_dict={net.input_actual: x,\n",
    "                                                                  net.target: y,\n",
    "                                                                  net.drop_out_rate: 0.})\n",
    "                    num_correct_samples += correct\n",
    "                # 计算在测试集上的准确率\n",
    "                testing_accuracy = num_correct_samples / float(num_samples)\n",
    "                print(\"\\t\\tClassifier test accuracy\", testing_accuracy)\n",
    "\n",
    "                gen_samples = sess.run(net.samples,feed_dict={net.input_latent_z: sample_z})\n",
    "                \n",
    "                samples.append(gen_samples)\n",
    "                \n",
    "                _,_ = view_generated_samples(-1, samples, 5, 10, figsize=figsize)\n",
    "\n",
    "\n",
    "                # 将准确率保存下来，接下来可能要看\n",
    "                train_accuracies.append(training_accuracy)\n",
    "                test_accuracies.append(testing_accuracy)\n",
    "            # 将会话给保存下来\n",
    "            saver.save(sess, './checkpoints/generator.ckpt')\n",
    "\n",
    "        # 将samples的属性值保存到文件samples.pkl中\n",
    "        with open('samples.pkl', 'wb') as f:\n",
    "            pkl.dump(samples, f)\n",
    "        return train_accuracies, test_accuracies, samples\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 定义数据集的大小\n",
    "real_size = (32,32,3)\n",
    "# 定义生成器生成的长度\n",
    "latent_space_z_size = 100\n",
    "# 学习的准确度\n",
    "learning_rate = 0.0003\n",
    "# 对GAN进行实例化\n",
    "net = GAN(real_size, latent_space_z_size, learning_rate)\n",
    "# 对Dataset进行实例化\n",
    "dataset = Dataset(train_data, test_data)\n",
    "# 每次训练时拿的数据量\n",
    "train_batch_size = 128\n",
    "# 总共进行5个周期的训练\n",
    "num_epochs = 5\n",
    "\n",
    "# 开始训练\n",
    "train_accuracies, test_accuracies, samples = train(net,dataset,num_epochs,train_batch_size,figsize=(10,5))\n",
    "\n",
    "# 设置画布，并显示模型在训练集和测试集上的准确率\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(train_accuracies, label='Train', alpha=0.5)\n",
    "plt.plot(test_accuracies, label='Test', alpha=0.5)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING:tensorflow:From <ipython-input-8-6588728a804a>:55: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "keep_dims is deprecated, use keepdims instead\n",
    "WARNING:tensorflow:From <ipython-input-9-1cee69543cc5>:32: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "\n",
    "Future major versions of TensorFlow will allow gradients to flow\n",
    "into the labels input on backprop by default.\n",
    "\n",
    "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
    "\n",
    "Epoch 0\n",
    "\t\tClassifier train accuracy:  0.179\n",
    "\t\tClassifier test accuracy 0.24746465888137675\n",
    "    \n",
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.2.png?raw=true)\n",
    "\n",
    "    Epoch 1\n",
    "\t\tClassifier train accuracy:  0.339\n",
    "\t\tClassifier test accuracy 0.433159188690842\n",
    " ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.3.png?raw=true)\n",
    "    \n",
    "   Epoch 2\n",
    "\t\tClassifier train accuracy:  0.539\n",
    "\t\tClassifier test accuracy 0.5295021511985248\n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.4.png?raw=true)\n",
    "    \n",
    "    Epoch 3\n",
    "\t\tClassifier train accuracy:  0.681\n",
    "\t\tClassifier test accuracy 0.6194683466502766\n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.5.png?raw=true)\n",
    "    \n",
    "    Epoch 4\n",
    "\t\tClassifier train accuracy:  0.807\n",
    "\t\tClassifier test accuracy 0.6441303011677935\n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.6.png?raw=true)\n",
    "    \n",
    "     <matplotlib.legend.Legend at 0x217ca6e2358>\n",
    "  \n",
    "   ![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.7.png?raw=true)  \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 此处会将之前显示的图片直接保存到电脑的硬盘中\n",
    "for ii in range(len(samples)):\n",
    "    fig,ax = view_generated_samples(ii, samples, 5, 10, figsize=(10,5))\n",
    "    fig.savefig('images/samples_{:03d}.png'.format(ii))\n",
    "    plt.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.8.png?raw=true)\n",
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.9.png?raw=true)\n",
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.10.png?raw=true)\n",
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.11.png?raw=true)\n",
    "![image](https://github.com/yanjiusheng2018/dlt/blob/master/src/content/Chapter15/chapter15_image/2.12.png?raw=true)\n",
    " \n",
    "   虽然特征匹配损失在半监督学习的任务中表现良好，但是生成器生成的图像不如前面章节创建的图像好。但是这个实现主要是为了演示我们如何使用用于半监督学习设置的GAN。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "最后，许多研究人员认为无监督学习是一般AI中缺失的环节系统。为克服这些障碍，尝试用较少的方法解决已确定的问题，标记数据是关键。在这种情况下，GAN为复杂学习提供了一个真正的选择，标记较少的样本的任务。然而，监督和半监督之间的绩效差距学习仍然远非平等。 我们当然可以期待这种差距随着新方法的发挥而变得更小。\n",
    "\n",
    "学号|姓名|专业\n",
    "-|-|-\n",
    "201802110533|张倩茹|概率论与数理统计\n",
    "201802110535|王悦|概率论与数理统计"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}